{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed = pd.read_csv('stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8675"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8651"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = stemmed['clean_posts']\n",
    "code = stemmed['encode']\n",
    "fixed_text = text[pd.notnull(text)]\n",
    "fixed_code = code[pd.notnull(text)]\n",
    "data = pd.DataFrame({'text': fixed_text, 'code': fixed_code})\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"final.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Naive Bayes once without cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test =  train_test_split(data, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 92302)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 92302)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, train.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21343930635838151"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted = clf.predict(X_train_tfidf)\n",
    "np.mean(train_predicted == train.code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21143847487001732"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(test.text)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "test_predicted = clf.predict(X_test_tfidf)\n",
    "np.mean(test_predicted == test.code)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Cross Validation\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>'&lt;URL&gt; &lt;URL&gt; enfp and intj moments  &lt;URL&gt;  spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>'Good one  _____   &lt;URL&gt; Of course, to which I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>'You're fired. That's another silly misconcept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                               text\n",
       "0     8  '<URL> <URL> enfp and intj moments  <URL>  spo...\n",
       "1     3  'I'm finding the lack of me in these posts ver...\n",
       "2    11  'Good one  _____   <URL> Of course, to which I...\n",
       "3    10  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     2  'You're fired. That's another silly misconcept..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test= train_test_split(data.text, data.code, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss': 'neg_log_loss',\n",
    "           'f1_micro': 'f1_micro'}\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "tfidf2 = CountVectorizer(ngram_range=(1, 1), \n",
    "                         stop_words='english',\n",
    "                         lowercase = True, \n",
    "                         max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_nb = Pipeline([('tfidf1', tfidf2), ('nb', MultinomialNB())])\n",
    "results_nb = cross_validate(model_nb, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.5424 (+/- 0.0073)\n",
      "CV F1: 0.5424 (+/- 0.0073)\n",
      "CV Logloss: 6.3304 (+/- 0.1587)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_acc']),\n",
    "                                                          np.std(results_nb['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_f1_micro']),\n",
    "                                                          np.std(results_nb['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_nb['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_nb['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54303870595031778"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb.fit(X_train, y_train)  \n",
    "test_predicted = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.55      0.26      0.35        47\n",
      "       ENTP       0.42      0.52      0.46       130\n",
      "       INTP       0.46      0.49      0.47        45\n",
      "       INTJ       0.49      0.49      0.49       169\n",
      "       ENTJ       0.33      0.17      0.22         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.29      0.08      0.12        26\n",
      "       ISFP       0.60      0.51      0.55       276\n",
      "       ISTP       0.58      0.69      0.63       367\n",
      "       ISFJ       0.58      0.57      0.57       223\n",
      "       ISTJ       0.61      0.66      0.63       249\n",
      "       ESTP       0.61      0.45      0.52        31\n",
      "       ESFP       0.22      0.21      0.21        43\n",
      "       ESTJ       0.67      0.38      0.48        42\n",
      "       ESFJ       0.43      0.51      0.46        57\n",
      "\n",
      "avg / total       0.54      0.54      0.54      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### account for class imbalance in naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Frequency of the elements in the List : ', Counter({9: 1828, 8: 1462, 11: 1301, 10: 1089, 3: 685, 1: 671, 15: 337, 13: 270, 2: 230, 14: 204, 0: 190, 12: 166, 7: 89, 5: 48, 4: 42, 6: 39}))\n",
      "[0.021962778869494857, 0.07756328748121605, 0.02658652178938851, 0.07918159750317882, 0.004854930065888337, 0.005548491503872385, 0.004508149346896312, 0.01028782799676338, 0.16899780372211304, 0.22286440873887411, 0.12588140099410472, 0.1503872384695411, 0.019188533117558665, 0.031210264709282162, 0.023581088891457633, 0.038955034100104036]\n"
     ]
    }
   ],
   "source": [
    "# find class weights \n",
    "import collections\n",
    "ctr = collections.Counter(data.code)\n",
    "print(\"Frequency of the elements in the List : \",ctr)\n",
    "freqs_2 = [190,671,230,685,42,48,39,89,1462,1928,1089,1301,166,270,204,337]\n",
    "class_priors_2 = [float(x) / len(data) for x in freqs_2]\n",
    "print class_priors_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.5424 (+/- 0.0075)\n",
      "CV F1: 0.5424 (+/- 0.0075)\n",
      "CV Logloss: 6.3320 (+/- 0.1589)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.52      0.26      0.34        47\n",
      "       ENTP       0.42      0.52      0.47       130\n",
      "       INTP       0.47      0.49      0.48        45\n",
      "       INTJ       0.50      0.50      0.50       169\n",
      "       ENTJ       0.33      0.17      0.22         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.25      0.08      0.12        26\n",
      "       ISFP       0.60      0.51      0.55       276\n",
      "       ISTP       0.58      0.70      0.63       367\n",
      "       ISFJ       0.58      0.57      0.57       223\n",
      "       ISTJ       0.61      0.66      0.63       249\n",
      "       ESTP       0.61      0.45      0.52        31\n",
      "       ESFP       0.23      0.21      0.22        43\n",
      "       ESTJ       0.67      0.38      0.48        42\n",
      "       ESFJ       0.43      0.51      0.47        57\n",
      "\n",
      "avg / total       0.54      0.54      0.54      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_nb_prior = Pipeline([('tfidf1', tfidf2), ('nb', MultinomialNB(class_prior = class_priors_2))])\n",
    "\n",
    "results_nb_prior = cross_validate(model_nb_prior, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb_prior['test_acc']),\n",
    "                                                          np.std(results_nb_prior['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb_prior['test_f1_micro']),\n",
    "                                                          np.std(results_nb_prior['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_nb_prior['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_nb_prior['test_neg_log_loss'])))\n",
    "model_nb_prior.fit(X_train, y_train)  \n",
    "test_predicted_prior = model_nb_prior.predict(X_test)\n",
    "print(metrics.classification_report(y_test, test_predicted_prior, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logisitic regression, C = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.5775 (+/- 0.0077)\n",
      "CV F1: 0.5775 (+/- 0.0077)\n",
      "CV Logloss: 2.0927 (+/- 0.0383)\n"
     ]
    }
   ],
   "source": [
    "model_lr_o = Pipeline([('tfidf1', tfidf2), ('lr', LogisticRegression(class_weight=\"balanced\"))])\n",
    "results_lr_o = cross_validate(model_lr_o, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)\n",
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr_o['test_acc']),\n",
    "                                                          np.std(results_lr_o['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr_o['test_f1_micro']),\n",
    "                                                          np.std(results_lr_o['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr_o['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr_o['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.52      0.26      0.34        47\n",
      "       ENTP       0.45      0.50      0.47       130\n",
      "       INTP       0.45      0.47      0.46        45\n",
      "       INTJ       0.55      0.49      0.52       169\n",
      "       ENTJ       0.40      0.33      0.36         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       1.00      0.22      0.36         9\n",
      "       ENFP       0.70      0.27      0.39        26\n",
      "       ISFP       0.55      0.56      0.55       276\n",
      "       ISTP       0.62      0.68      0.65       367\n",
      "       ISFJ       0.55      0.56      0.55       223\n",
      "       ISTJ       0.55      0.61      0.58       249\n",
      "       ESTP       0.47      0.45      0.46        31\n",
      "       ESFP       0.32      0.37      0.34        43\n",
      "       ESTJ       0.65      0.40      0.50        42\n",
      "       ESFJ       0.44      0.42      0.43        57\n",
      "\n",
      "avg / total       0.55      0.54      0.54      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lr_o.fit(X_train, y_train)  \n",
    "test_predicted_lr_o = model_lr_o.predict(X_test)\n",
    "print(metrics.classification_report(y_test, test_predicted_lr_o, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression with regularization strength C = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr_only = LogisticRegression(class_weight=\"balanced\", C=0.005)\n",
    "model_lr = Pipeline([('tfidf1', tfidf2), ('lr', model_lr_only )])\n",
    "results_lr = cross_validate(model_lr, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6568 (+/- 0.0036)\n",
      "CV F1: 0.6568 (+/- 0.0036)\n",
      "CV Logloss: 1.2993 (+/- 0.0109)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_acc']),\n",
    "                                                          np.std(results_lr['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_f1_micro']),\n",
    "                                                          np.std(results_lr['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr.fit(X_train, y_train)  \n",
    "test_predicted_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.51      0.40      0.45        47\n",
      "       ENTP       0.60      0.61      0.61       130\n",
      "       INTP       0.42      0.56      0.48        45\n",
      "       INTJ       0.68      0.62      0.65       169\n",
      "       ENTJ       0.22      0.33      0.27         6\n",
      "       ENFJ       0.08      0.09      0.09        11\n",
      "       INFP       0.67      0.44      0.53         9\n",
      "       ENFP       0.67      0.38      0.49        26\n",
      "       ISFP       0.69      0.61      0.65       276\n",
      "       ISTP       0.73      0.75      0.74       367\n",
      "       ISFJ       0.68      0.67      0.68       223\n",
      "       ISTJ       0.66      0.70      0.68       249\n",
      "       ESTP       0.46      0.61      0.53        31\n",
      "       ESFP       0.42      0.44      0.43        43\n",
      "       ESTJ       0.63      0.62      0.63        42\n",
      "       ESFJ       0.49      0.65      0.56        57\n",
      "\n",
      "avg / total       0.65      0.64      0.64      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_lr, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6568 (+/- 0.0036)\n",
      "CV F1: 0.6568 (+/- 0.0036)\n",
      "CV Logloss: 1.2993 (+/- 0.0109)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.51      0.40      0.45        47\n",
      "       ENTP       0.60      0.61      0.61       130\n",
      "       INTP       0.42      0.56      0.48        45\n",
      "       INTJ       0.68      0.62      0.65       169\n",
      "       ENTJ       0.22      0.33      0.27         6\n",
      "       ENFJ       0.08      0.09      0.09        11\n",
      "       INFP       0.67      0.44      0.53         9\n",
      "       ENFP       0.67      0.38      0.49        26\n",
      "       ISFP       0.69      0.61      0.65       276\n",
      "       ISTP       0.73      0.75      0.74       367\n",
      "       ISFJ       0.68      0.67      0.68       223\n",
      "       ISTJ       0.66      0.70      0.68       249\n",
      "       ESTP       0.46      0.61      0.53        31\n",
      "       ESFP       0.42      0.44      0.43        43\n",
      "       ESTJ       0.63      0.62      0.63        42\n",
      "       ESFJ       0.49      0.65      0.56        57\n",
      "\n",
      "avg / total       0.65      0.64      0.64      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# l2 regularization \n",
    "model_lr_l2_only = LogisticRegression(class_weight=\"balanced\", C=0.005, penalty = \"l2\")\n",
    "model_lr_l2 = Pipeline([('tfidf1', tfidf2), ('lr', model_lr_l2_only)])\n",
    "results_lr_l2 = cross_validate(model_lr_l2, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)\n",
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr_l2['test_acc']),\n",
    "                                                          np.std(results_lr_l2['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr_l2['test_f1_micro']),\n",
    "                                                          np.std(results_lr_l2['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr_l2['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr_l2['test_neg_log_loss'])))\n",
    "                                                          \n",
    "                                                          \n",
    "model_lr_l2.fit(X_train, y_train)  \n",
    "test_predicted_lr_l2 = model_lr_l2.predict(X_test)\n",
    "print(metrics.classification_report(y_test, test_predicted_lr_l2, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare coefficients after l2 to model_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00739501,  0.0098344 , -0.04395071, ...,  0.01750716,\n",
       "        -0.00645795, -0.01776871],\n",
       "       [ 0.01126405,  0.00780299, -0.0348618 , ..., -0.00593112,\n",
       "        -0.00306147, -0.01587556],\n",
       "       [-0.01415709,  0.00790119, -0.06750588, ..., -0.0218618 ,\n",
       "        -0.00805412, -0.03408169],\n",
       "       ..., \n",
       "       [ 0.04030511, -0.01040178, -0.02188338, ..., -0.01597301,\n",
       "        -0.00132489,  0.06999554],\n",
       "       [-0.02029069,  0.00659794, -0.04063186, ...,  0.01633387,\n",
       "         0.00588759,  0.02858284],\n",
       "       [-0.01769814, -0.02182906, -0.00814406, ..., -0.00023377,\n",
       "         0.00501872, -0.01986842]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr_l2_only.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6040 (+/- 0.0101)\n",
      "CV F1: 0.6040 (+/- 0.0101)\n",
      "CV Logloss: 1.7499 (+/- 0.0206)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.60      0.45      0.51        47\n",
      "       ENTP       0.57      0.54      0.56       130\n",
      "       INTP       0.49      0.56      0.52        45\n",
      "       INTJ       0.72      0.56      0.63       169\n",
      "       ENTJ       0.17      0.50      0.25         6\n",
      "       ENFJ       0.05      0.27      0.09        11\n",
      "       INFP       0.13      0.56      0.21         9\n",
      "       ENFP       0.45      0.54      0.49        26\n",
      "       ISFP       0.66      0.56      0.60       276\n",
      "       ISTP       0.66      0.70      0.68       367\n",
      "       ISFJ       0.67      0.60      0.64       223\n",
      "       ISTJ       0.64      0.61      0.63       249\n",
      "       ESTP       0.45      0.55      0.49        31\n",
      "       ESFP       0.40      0.49      0.44        43\n",
      "       ESTJ       0.53      0.55      0.54        42\n",
      "       ESFJ       0.53      0.54      0.53        57\n",
      "\n",
      "avg / total       0.62      0.59      0.60      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# l1 regularization \n",
    "model_lr_l1_only = LogisticRegression(class_weight=\"balanced\", C=0.005, penalty = \"l1\")\n",
    "model_lr_l1 = Pipeline([('tfidf1', tfidf2), ('lr', model_lr_l1_only)])\n",
    "\n",
    "results_lr_l1 = cross_validate(model_lr_l1, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)\n",
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr_l1['test_acc']),\n",
    "                                                          np.std(results_lr_l1['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr_l1['test_f1_micro']),\n",
    "                                                          np.std(results_lr_l1['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr_l1['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr_l1['test_neg_log_loss'])))\n",
    "                                                          \n",
    "                                                          \n",
    "model_lr_l1.fit(X_train, y_train)  \n",
    "test_predicted_lr_l1 = model_lr_l1.predict(X_test)\n",
    "print(metrics.classification_report(y_test, test_predicted_lr_l1, target_names=unique_type_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of the coefficient matrix is (16, 5000)\n",
      "There are a total of 80000 coefficients\n"
     ]
    }
   ],
   "source": [
    "print 'The dimension of the coefficient matrix is', model_lr_l1_only.coef_.shape\n",
    "total =  model_lr_l1_only.coef_.shape[0] * model_lr_l1_only.coef_.shape[1]\n",
    "print 'There are a total of',total, 'coefficients'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of non-zero coefficients are 276\n",
      "Percentage: 0.345 %\n"
     ]
    }
   ],
   "source": [
    "print 'The number of non-zero coefficients are', total - sum(x == 0 for row in model_lr_l1_only.coef_ for x in row)\n",
    "print 'Percentage:', float((total - sum(x == 0 for row in model_lr_l1_only.coef_ for x in row)))/float(total) * 100, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based methods\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 20, max_depth=4, n_jobs = -1)\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "model_etc = Pipeline([('tfidf1', tfidf2), ('tsvd1', tsvd), ('etc', etc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_etc = cross_validate(model_etc, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.2419 (+/- 0.0101)\n",
      "CV F1: 0.2419 (+/- 0.0101)\n",
      "CV Logloss: 2.2172 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_etc['test_acc']),\n",
    "                                                          np.std(results_etc['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_etc['test_f1_micro']),\n",
    "                                                          np.std(results_etc['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_etc['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_etc['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_etc.fit(X_train, y_train)  \n",
    "test_predicted_etc = model_etc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.00      0.00      0.00        47\n",
      "       ENTP       0.00      0.00      0.00       130\n",
      "       INTP       0.00      0.00      0.00        45\n",
      "       INTJ       0.00      0.00      0.00       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.45      0.05      0.09       276\n",
      "       ISTP       0.24      0.98      0.38       367\n",
      "       ISFJ       1.00      0.02      0.04       223\n",
      "       ISTJ       0.29      0.21      0.24       249\n",
      "       ESTP       0.00      0.00      0.00        31\n",
      "       ESFP       0.00      0.00      0.00        43\n",
      "       ESTJ       0.00      0.00      0.00        42\n",
      "       ESFJ       0.00      0.00      0.00        57\n",
      "\n",
      "avg / total       0.29      0.25      0.13      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_etc, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = DecisionTreeClassifier()\n",
    "model_rf = Pipeline([('tfidf1', tfidf2), ('rf', rf)])\n",
    "results_rf = cross_validate(model_rf, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.4619 (+/- 0.0152)\n",
      "CV F1: 0.4619 (+/- 0.0152)\n",
      "CV Logloss: 18.5373 (+/- 0.5327)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_rf['test_acc']),\n",
    "                                                          np.std(results_rf['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_rf['test_f1_micro']),\n",
    "                                                          np.std(results_rf['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_rf['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_rf['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf.fit(X_train, y_train)  \n",
    "test_predicted_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.16      0.13      0.14        47\n",
      "       ENTP       0.40      0.48      0.44       130\n",
      "       INTP       0.14      0.09      0.11        45\n",
      "       INTJ       0.50      0.43      0.46       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.11      0.11      0.11         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.47      0.52      0.49       276\n",
      "       ISTP       0.55      0.56      0.55       367\n",
      "       ISFJ       0.47      0.47      0.47       223\n",
      "       ISTJ       0.50      0.53      0.51       249\n",
      "       ESTP       0.22      0.26      0.24        31\n",
      "       ESFP       0.25      0.23      0.24        43\n",
      "       ESTJ       0.32      0.24      0.27        42\n",
      "       ESFJ       0.45      0.37      0.40        57\n",
      "\n",
      "avg / total       0.44      0.45      0.45      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_rf, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Random Forest Classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/hadend/tuning-random-forest-parameters\n",
    "\n",
    "max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "max_features : int, float, string or None, optional (default=”auto”)\n",
    "The number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tune depths of trees and max features \n",
    "parameters = {'rf__max_depth': [10,11,12,13,14,15,16,17,18,19,20],\n",
    "              'rf__max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 84)\n",
    "model_tune = Pipeline([('tfidf1', tfidf2), ('rf', rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_rf =  GridSearchCV(model_tune, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_results = gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('tfidf1', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "   ...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=84, verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'rf__max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'rf__max_features': ['auto', 'sqrt']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.398843930636\n",
      "rf__max_depth: 19\n",
      "rf__max_features: 'auto'\n"
     ]
    }
   ],
   "source": [
    "print(gs_results.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_results.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(random_state = 84, max_depth = 19, max_features = 'auto')\n",
    "model_rf_best = model_tune = Pipeline([('tfidf1', tfidf2), ('rf_best', rf_best)])\n",
    "model_rf_best.fit(X_train, y_train)  \n",
    "test_predicted_rf_best = model_rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.00      0.00      0.00        47\n",
      "       ENTP       0.38      0.16      0.23       130\n",
      "       INTP       0.62      0.11      0.19        45\n",
      "       INTJ       0.46      0.20      0.28       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.42      0.51      0.46       276\n",
      "       ISTP       0.40      0.76      0.52       367\n",
      "       ISFJ       0.44      0.42      0.43       223\n",
      "       ISTJ       0.42      0.51      0.46       249\n",
      "       ESTP       0.00      0.00      0.00        31\n",
      "       ESFP       0.11      0.02      0.04        43\n",
      "       ESTJ       0.50      0.07      0.12        42\n",
      "       ESFJ       0.45      0.18      0.25        57\n",
      "\n",
      "avg / total       0.39      0.41      0.37      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_rf_best, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65049104563835936"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None))])\n",
    "model_svm.fit(X_train, y_train)  \n",
    "predicted_svm = model_svm.predict(X_test)\n",
    "np.mean(predicted_svm == y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_svm = cross_validate(model_svm, X_train, y_train, cv=kfolds, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6234 (+/- 0.0301)\n"
     ]
    }
   ],
   "source": [
    "# print(result_svm)\n",
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(result_svm['test_score']),\n",
    "                                                           np.std(result_svm['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_svm.fit(X_train, y_train)  \n",
    "test_predicted_svm = model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       1.00      0.17      0.29        47\n",
      "       ENTP       0.65      0.52      0.58       130\n",
      "       INTP       0.64      0.40      0.49        45\n",
      "       INTJ       0.71      0.60      0.65       169\n",
      "       ENTJ       0.67      0.33      0.44         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       1.00      0.15      0.27        26\n",
      "       ISFP       0.61      0.68      0.65       276\n",
      "       ISTP       0.63      0.88      0.73       367\n",
      "       ISFJ       0.68      0.70      0.69       223\n",
      "       ISTJ       0.64      0.78      0.70       249\n",
      "       ESTP       0.71      0.39      0.50        31\n",
      "       ESFP       0.71      0.23      0.35        43\n",
      "       ESTJ       0.73      0.38      0.50        42\n",
      "       ESFJ       0.77      0.42      0.55        57\n",
      "\n",
      "avg / total       0.66      0.65      0.63      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_svm, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune SVM with GridSearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "               'clf__alpha': (1e-2, 1e-3,1e-4,2e-4)}\n",
    "gs_svm = GridSearchCV(model_svm, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_svm = gs_svm.fit(X_train[:1500], y_train[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "     print(\"%s: %r\" % (param_name, gs_svm.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turns out our original parameters were the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the relationship between different predictors \n",
    "https://stackoverflow.com/questions/29432629/correlation-matrix-using-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# correlation matrix for predictors \n",
    "tfidf2 = CountVectorizer(ngram_range=(1, 1), \n",
    "                         stop_words='english',\n",
    "                         lowercase = True, \n",
    "                         max_features = 5000)                         \n",
    "X_train_tfidf = tfidf2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_train_tfidf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...   4990  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
       "\n",
       "   4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     1     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smaller_df = df.iloc[:,0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(smaller_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternatively we can use sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alternative - sns\n",
    "sns.pairplot(smaller_df)\n",
    "f, ax = pl.subplots(figsize=(10, 10))\n",
    "corr = smaller_df.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
