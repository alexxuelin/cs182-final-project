{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "py.init_notebook_mode(connected=True)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed = pd.read_csv('stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8675"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8651"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = stemmed['clean_posts']\n",
    "code = stemmed['encode']\n",
    "fixed_text = text[pd.notnull(text)]\n",
    "fixed_code = code[pd.notnull(text)]\n",
    "data = pd.DataFrame({'text': fixed_text, 'code': fixed_code})\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"final.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Naive Bayes without cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test =  train_test_split(data, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 92302)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 92302)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21343930635838151"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted = clf.predict(X_train_tfidf)\n",
    "np.mean(train_predicted == train.code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21143847487001732"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(test.text)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "test_predicted = clf.predict(X_test_tfidf)\n",
    "np.mean(test_predicted == test.code)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Cross Validation\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>'&lt;URL&gt; &lt;URL&gt; enfp and intj moments  &lt;URL&gt;  spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>'Good one  _____   &lt;URL&gt; Of course, to which I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>'You're fired. That's another silly misconcept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                               text\n",
       "0     8  '<URL> <URL> enfp and intj moments  <URL>  spo...\n",
       "1     3  'I'm finding the lack of me in these posts ver...\n",
       "2    11  'Good one  _____   <URL> Of course, to which I...\n",
       "3    10  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     2  'You're fired. That's another silly misconcept..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train tet split\n",
    "X_train, X_test, y_train, y_test= train_test_split(data.text, data.code, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss': 'neg_log_loss',\n",
    "           'f1_micro': 'f1_micro'}\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "tfidf2 = CountVectorizer(ngram_range=(1, 1), \n",
    "                         stop_words='english',\n",
    "                         lowercase = True, \n",
    "                         max_features = 5000)\n",
    "model_nb = Pipeline([('tfidf1', tfidf2), ('nb', MultinomialNB())])\n",
    "results_nb = cross_validate(model_nb, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.5424 (+/- 0.0073)\n",
      "CV F1: 0.5424 (+/- 0.0073)\n",
      "CV Logloss: 6.3304 (+/- 0.1587)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_acc']),\n",
    "                                                          np.std(results_nb['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_f1_micro']),\n",
    "                                                          np.std(results_nb['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_nb['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_nb['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54303870595031778"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb.fit(X_train, y_train)  \n",
    "test_predicted = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.55      0.26      0.35        47\n",
      "       ENTP       0.42      0.52      0.46       130\n",
      "       INTP       0.46      0.49      0.47        45\n",
      "       INTJ       0.49      0.49      0.49       169\n",
      "       ENTJ       0.33      0.17      0.22         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.29      0.08      0.12        26\n",
      "       ISFP       0.60      0.51      0.55       276\n",
      "       ISTP       0.58      0.69      0.63       367\n",
      "       ISFJ       0.58      0.57      0.57       223\n",
      "       ISTJ       0.61      0.66      0.63       249\n",
      "       ESTP       0.61      0.45      0.52        31\n",
      "       ESFP       0.22      0.21      0.21        43\n",
      "       ESTJ       0.67      0.38      0.48        42\n",
      "       ESFJ       0.43      0.51      0.46        57\n",
      "\n",
      "avg / total       0.54      0.54      0.54      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr = Pipeline([('tfidf1', tfidf2), ('lr', LogisticRegression(class_weight=\"balanced\", C=0.005))])\n",
    "results_lr = cross_validate(model_lr, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6568 (+/- 0.0036)\n",
      "CV F1: 0.6568 (+/- 0.0036)\n",
      "CV Logloss: 1.2993 (+/- 0.0109)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_acc']),\n",
    "                                                          np.std(results_lr['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_f1_micro']),\n",
    "                                                          np.std(results_lr['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr.fit(X_train, y_train)  \n",
    "test_predicted_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.51      0.40      0.45        47\n",
      "       ENTP       0.60      0.61      0.61       130\n",
      "       INTP       0.42      0.56      0.48        45\n",
      "       INTJ       0.68      0.62      0.65       169\n",
      "       ENTJ       0.22      0.33      0.27         6\n",
      "       ENFJ       0.08      0.09      0.09        11\n",
      "       INFP       0.67      0.44      0.53         9\n",
      "       ENFP       0.67      0.38      0.49        26\n",
      "       ISFP       0.69      0.61      0.65       276\n",
      "       ISTP       0.73      0.75      0.74       367\n",
      "       ISFJ       0.68      0.67      0.68       223\n",
      "       ISTJ       0.66      0.70      0.68       249\n",
      "       ESTP       0.46      0.61      0.53        31\n",
      "       ESFP       0.42      0.44      0.43        43\n",
      "       ESTJ       0.63      0.62      0.63        42\n",
      "       ESFJ       0.49      0.65      0.56        57\n",
      "\n",
      "avg / total       0.65      0.64      0.64      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_lr, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based methods\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 20, max_depth=4, n_jobs = -1)\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "model_etc = Pipeline([('tfidf1', tfidf2), ('tsvd1', tsvd), ('etc', etc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_etc = cross_validate(model_etc, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.2419 (+/- 0.0101)\n",
      "CV F1: 0.2419 (+/- 0.0101)\n",
      "CV Logloss: 2.2172 (+/- 0.0021)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_etc['test_acc']),\n",
    "                                                          np.std(results_etc['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_etc['test_f1_micro']),\n",
    "                                                          np.std(results_etc['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_etc['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_etc['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_etc.fit(X_train, y_train)  \n",
    "test_predicted_etc = model_etc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.00      0.00      0.00        47\n",
      "       ENTP       0.00      0.00      0.00       130\n",
      "       INTP       0.00      0.00      0.00        45\n",
      "       INTJ       0.00      0.00      0.00       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.45      0.05      0.09       276\n",
      "       ISTP       0.24      0.98      0.38       367\n",
      "       ISFJ       1.00      0.02      0.04       223\n",
      "       ISTJ       0.29      0.21      0.24       249\n",
      "       ESTP       0.00      0.00      0.00        31\n",
      "       ESFP       0.00      0.00      0.00        43\n",
      "       ESTJ       0.00      0.00      0.00        42\n",
      "       ESFJ       0.00      0.00      0.00        57\n",
      "\n",
      "avg / total       0.29      0.25      0.13      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_etc, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = DecisionTreeClassifier()\n",
    "model_rf = Pipeline([('tfidf1', tfidf2), ('rf', rf)])\n",
    "results_rf = cross_validate(model_rf, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.4619 (+/- 0.0152)\n",
      "CV F1: 0.4619 (+/- 0.0152)\n",
      "CV Logloss: 18.5373 (+/- 0.5327)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_rf['test_acc']),\n",
    "                                                          np.std(results_rf['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_rf['test_f1_micro']),\n",
    "                                                          np.std(results_rf['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_rf['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_rf['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rf.fit(X_train, y_train)  \n",
    "test_predicted_rf = model_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.16      0.13      0.14        47\n",
      "       ENTP       0.40      0.48      0.44       130\n",
      "       INTP       0.14      0.09      0.11        45\n",
      "       INTJ       0.50      0.43      0.46       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.11      0.11      0.11         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.47      0.52      0.49       276\n",
      "       ISTP       0.55      0.56      0.55       367\n",
      "       ISFJ       0.47      0.47      0.47       223\n",
      "       ISTJ       0.50      0.53      0.51       249\n",
      "       ESTP       0.22      0.26      0.24        31\n",
      "       ESFP       0.25      0.23      0.24        43\n",
      "       ESTJ       0.32      0.24      0.27        42\n",
      "       ESFJ       0.45      0.37      0.40        57\n",
      "\n",
      "avg / total       0.44      0.45      0.45      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_rf, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Random Forest Classifier using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/hadend/tuning-random-forest-parameters\n",
    "\n",
    "max_depth: The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "max_features : int, float, string or None, optional (default=”auto”)\n",
    "The number of features to consider when looking for the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tune depths of trees and max features \n",
    "parameters = {'rf__max_depth': [10,11,12,13,14,15,16,17,18,19,20],\n",
    "              'rf__max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 84)\n",
    "model_tune = Pipeline([('tfidf1', tfidf2), ('rf', rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_rf =  GridSearchCV(model_tune, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_results = gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('tfidf1', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "   ...stimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=84, verbose=0, warm_start=False))]),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid={'rf__max_depth': [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'rf__max_features': ['auto', 'sqrt']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print gs_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.398843930636\n",
      "rf__max_depth: 19\n",
      "rf__max_features: 'auto'\n"
     ]
    }
   ],
   "source": [
    "print(gs_results.best_score_)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_results.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_best = RandomForestClassifier(random_state = 84, max_depth = 19, max_features = 'auto')\n",
    "model_rf_best = model_tune = Pipeline([('tfidf1', tfidf2), ('rf_best', rf_best)])\n",
    "model_rf_best.fit(X_train, y_train)  \n",
    "test_predicted_rf_best = model_rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.00      0.00      0.00        47\n",
      "       ENTP       0.38      0.16      0.23       130\n",
      "       INTP       0.62      0.11      0.19        45\n",
      "       INTJ       0.46      0.20      0.28       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.42      0.51      0.46       276\n",
      "       ISTP       0.40      0.76      0.52       367\n",
      "       ISFJ       0.44      0.42      0.43       223\n",
      "       ISTJ       0.42      0.51      0.46       249\n",
      "       ESTP       0.00      0.00      0.00        31\n",
      "       ESFP       0.11      0.02      0.04        43\n",
      "       ESTJ       0.50      0.07      0.12        42\n",
      "       ESFJ       0.45      0.18      0.25        57\n",
      "\n",
      "avg / total       0.39      0.41      0.37      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_rf_best, target_names=unique_type_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
