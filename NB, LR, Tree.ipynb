{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "py.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed = pd.read_csv('stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8675"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8651"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = stemmed['clean_posts']\n",
    "code = stemmed['encode']\n",
    "fixed_text = text[pd.notnull(text)]\n",
    "fixed_code = code[pd.notnull(text)]\n",
    "data = pd.DataFrame({'text': fixed_text, 'code': fixed_code})\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"final.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Naive Bayes without cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test =  train_test_split(data, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 92302)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.text)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 92302)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21343930635838151"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predicted = clf.predict(X_train_tfidf)\n",
    "np.mean(train_predicted == train.code) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21143847487001732"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform(test.text)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "test_predicted = clf.predict(X_test_tfidf)\n",
    "np.mean(test_predicted == test.code)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>'&lt;URL&gt; &lt;URL&gt; enfp and intj moments  &lt;URL&gt;  spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>'Good one  _____   &lt;URL&gt; Of course, to which I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>'You're fired. That's another silly misconcept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                               text\n",
       "0     8  '<URL> <URL> enfp and intj moments  <URL>  spo...\n",
       "1     3  'I'm finding the lack of me in these posts ver...\n",
       "2    11  'Good one  _____   <URL> Of course, to which I...\n",
       "3    10  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     2  'You're fired. That's another silly misconcept..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test= train_test_split(data.text, data.code, test_size=0.2, random_state=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "scoring = {'acc': 'accuracy',\n",
    "           'neg_log_loss': 'neg_log_loss',\n",
    "           'f1_micro': 'f1_micro'}\n",
    "kfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "tfidf2 = CountVectorizer(ngram_range=(1, 1), \n",
    "                         stop_words='english',\n",
    "                         lowercase = True, \n",
    "                         max_features = 5000)\n",
    "model_nb = Pipeline([('tfidf1', tfidf2), ('nb', MultinomialNB())])\n",
    "results_nb = cross_validate(model_nb, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.5424 (+/- 0.0073)\n",
      "CV F1: 0.5424 (+/- 0.0073)\n",
      "CV Logloss: 6.3304 (+/- 0.1587)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_acc']),\n",
    "                                                          np.std(results_nb['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_nb['test_f1_micro']),\n",
    "                                                          np.std(results_nb['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_nb['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_nb['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb.fit(X_train, y_train)  \n",
    "test_predicted = model_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.55      0.26      0.35        47\n",
      "       ENTP       0.42      0.52      0.46       130\n",
      "       INTP       0.46      0.49      0.47        45\n",
      "       INTJ       0.49      0.49      0.49       169\n",
      "       ENTJ       0.33      0.17      0.22         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.29      0.08      0.12        26\n",
      "       ISFP       0.60      0.51      0.55       276\n",
      "       ISTP       0.58      0.69      0.63       367\n",
      "       ISFJ       0.58      0.57      0.57       223\n",
      "       ISTJ       0.61      0.66      0.63       249\n",
      "       ESTP       0.61      0.45      0.52        31\n",
      "       ESFP       0.22      0.21      0.21        43\n",
      "       ESTJ       0.67      0.38      0.48        42\n",
      "       ESFJ       0.43      0.51      0.46        57\n",
      "\n",
      "avg / total       0.54      0.54      0.54      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lr = Pipeline([('tfidf1', tfidf2), ('lr', LogisticRegression(class_weight=\"balanced\", C=0.005))])\n",
    "results_lr = cross_validate(model_lr, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy: 0.6568 (+/- 0.0036)\n",
      "CV F1: 0.6568 (+/- 0.0036)\n",
      "CV Logloss: 1.2993 (+/- 0.0109)\n"
     ]
    }
   ],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_acc']),\n",
    "                                                          np.std(results_lr['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_f1_micro']),\n",
    "                                                          np.std(results_lr['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_lr['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.fit(X_train, y_train)  \n",
    "test_predicted_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.51      0.40      0.45        47\n",
      "       ENTP       0.60      0.61      0.61       130\n",
      "       INTP       0.42      0.56      0.48        45\n",
      "       INTJ       0.68      0.62      0.65       169\n",
      "       ENTJ       0.22      0.33      0.27         6\n",
      "       ENFJ       0.08      0.09      0.09        11\n",
      "       INFP       0.67      0.44      0.53         9\n",
      "       ENFP       0.67      0.38      0.49        26\n",
      "       ISFP       0.69      0.61      0.65       276\n",
      "       ISTP       0.73      0.75      0.74       367\n",
      "       ISFJ       0.68      0.67      0.68       223\n",
      "       ISTJ       0.66      0.70      0.68       249\n",
      "       ESTP       0.46      0.61      0.53        31\n",
      "       ESFP       0.42      0.44      0.43        43\n",
      "       ESTJ       0.63      0.62      0.63        42\n",
      "       ESFJ       0.49      0.65      0.56        57\n",
      "\n",
      "avg / total       0.65      0.64      0.64      1731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_lr, target_names=unique_type_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree based methods\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 20, max_depth=4, n_jobs = -1)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "tsvd = TruncatedSVD(n_components=10)\n",
    "model_etc = Pipeline([('tfidf1', tfidf), ('tsvd1', tsvd), ('etc', etc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_etc = cross_validate(model_etc, X_train, y_train, cv=kfolds, scoring=scoring, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CV Accuracy: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_etc['test_acc']),\n",
    "                                                          np.std(results_etc['test_acc'])))\n",
    "print(\"CV F1: {:0.4f} (+/- {:0.4f})\".format(np.mean(results_lr['test_f1_micro']),\n",
    "                                                          np.std(results_etc['test_f1_micro'])))\n",
    "print(\"CV Logloss: {:0.4f} (+/- {:0.4f})\".format(np.mean(-1*results_lr['test_neg_log_loss']),\n",
    "                                                          np.std(-1*results_etc['test_neg_log_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_etc.fit(X_train, y_train)  \n",
    "test_predicted_etc = model_etc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       INFJ       0.00      0.00      0.00        47\n",
      "       ENTP       0.00      0.00      0.00       130\n",
      "       INTP       0.00      0.00      0.00        45\n",
      "       INTJ       0.00      0.00      0.00       169\n",
      "       ENTJ       0.00      0.00      0.00         6\n",
      "       ENFJ       0.00      0.00      0.00        11\n",
      "       INFP       0.00      0.00      0.00         9\n",
      "       ENFP       0.00      0.00      0.00        26\n",
      "       ISFP       0.48      0.20      0.28       276\n",
      "       ISTP       0.27      0.92      0.42       367\n",
      "       ISFJ       1.00      0.02      0.04       223\n",
      "       ISTJ       0.37      0.55      0.44       249\n",
      "       ESTP       0.00      0.00      0.00        31\n",
      "       ESFP       0.00      0.00      0.00        43\n",
      "       ESTJ       0.00      0.00      0.00        42\n",
      "       ESFJ       0.00      0.00      0.00        57\n",
      "\n",
      "avg / total       0.32      0.31      0.20      1731\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, test_predicted_etc, target_names=unique_type_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
